<template lang="pug">
.curso-main-container.pb-3
  BannerInterno
  .container.tarjeta.tarjeta--blanca.p-4.p-md-5.mb-5
    .titulo-principal.color-acento-contenido
      .titulo-principal__numero
        span 3
      h1 Algoritmos de aprendizaje supervisado en acci√≥n con Python
    
    p(data-aos="fade-right") Incluyen algoritmos que toman una muestra de datos y sus respectivas salidas, el objetivo principal es que el algoritmo aprenda c√≥mo se relacionan los datos de entrada X y sus correspondientes salidas Y, a partir de un conjunto de entrenamiento escogido para tal fin.

    p.mb-5.fw-bold(data-aos="fade-right") Con el conocimiento adquirido se puede predecir nuevas salidas a trav√©s de nuevos datos X

    .bloque-texto-g.bloque-texto-g-edit.color-primario.p-3.p-sm-4.p-md-5.col-xl-10.mx-auto(data-aos="fade-right")
      .bloque-texto-g__img(
        :style="{'background-image': `url(${require('@/assets/curso/temas/tema3/img-1.png')})`}"
      )
      .bloque-texto-g__texto.p-4
        p.mb-0 Estos algoritmos se llaman supervisados porque el modelo aprendi√≥ de respuestas y etiquetas conocidas de antemano en la fase de entrenamiento. Los m√©todos de aprendizaje supervisado son de dos tipos principales, esto depende del problema que se desea resolver y pueden ser: algoritmos de regresi√≥n y algoritmos de clasificaci√≥n.
    Separador
    #t_3_1.titulo-segundo.color-acento-contenido
      h2 3.1  Algoritmo de regresi√≥n con Python
    
    p(data-aos="fade-right") La regresi√≥n lineal se utiliza para estimar valores reales como ventas, costos, cantidad de llamadas en una central, gastos, etc., en funci√≥n de unas variables predictoras de tipo continuo. <b>La mejor ecuaci√≥n que se ajusta se llama l√≠nea de regresi√≥n y la ecuaci√≥n utilizada es:</b>

    .d-flex.flex-wrap.mb-5
      .col-md-6.d-flex.flex-wrap.order-2.order-md-1
        .d-flex.pe-md-3.mb-3
          .tarjeta.p-3.p-md-4.mb-auto(style="background-color: #24135A;" data-aos="fade-left")
            p.mb-0(style="color: #FFD945") ùëå = ùëöùëã+ùëè
        .d-flex.pe-md-4.mb-4.col-12.col-lg
          .tarjeta.p-3.p-md-4.w-100(style="background-color: #E2F8F0;" data-aos="fade-left")
            p.fw-bold Donde:
            p.mb-0 ùëå: es la variable dependiente.
              br            
              |ùëö: es la pendiente de la l√≠nea de regresi√≥n.
              br              
              |ùëè: es la intersecci√≥n con el eje Y.
        p.pe-md-4(data-aos="fade-right") La regresi√≥n lineal puede ser simple o m√∫ltiple, la primera se caracteriza por tener una variable independiente, contrario a la regresi√≥n m√∫ltiple que se caracteriza por tener m√°s de una variable independiente.
        p.mb-0.pe-lg-4(data-aos="fade-right") Volviendo al ejemplo propuesto se utilizar√° la librer√≠a <em><b style="background-color: #E1E2FC">scikit-learn,</b></em> que es una librer√≠a para el aprendizaje autom√°tico. En el siguiente recurso se pueden identificar los m√≥dulos a implementar y los pasos a seguir:
      img.mx-auto.mx-md-0.col-md-6.col-xl-5.mb-4.mb-md-auto.order-1.order-md-2(src="@/assets/curso/temas/tema3/img-2.png" style="max-width: 492px" data-aos="fade-left")
    
    .tarjeta.p-5(style="background-color: #EBECFF")
      LineaTiempoC.color-acento-contenido(text-small)
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso 1")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Lo primero que se debe tener en cuenta es que: 
            p linear_model: sirve para entrenar un modelo de Machine Learning de regresi√≥n lineal. 
              br            
              |#[b train_test_split:] sirve para dividir los datos en datos de entrenamiento y datos de prueba. 
              br              
              |#[b metrics:] sirve para medir el desempe√±o del modelo.
            p.fw-bold En ese orden de ideas el c√≥digo a utilizar es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white import seaborn as sns 
                  br                
                  |import matplotlib.pyplot as plt 
                  br                  
                  |from sklearn.linear_model import LinearRegression 
                  br                  
                  |from sklearn.model_selection import train_test_split 
                  br                  
                  |from sklearn.metrics import mean_squared_error, r2_score
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-3.svg" style="max-width: 290px" data-aos="fade-left")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso 2")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Para entrenar el modelo con esta librer√≠a inicialmente se carga el valor de X con los datos de la longitud de la aleta #[b (flipper_length_mm)], y Y con los datos de masa del ping√ºino #[b (body_mass_g)], posteriormente se obtiene un subconjunto de datos que ser√°n el dataset de entrenamiento y el set de pruebas en las variables #[b X_train, Y_train, X_test, Y_test] en una proporci√≥n de 80 % para los datos de entrenamiento y 20 % para los datos de prueba.
            p.fw-bold El c√≥digo a utilizar es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white X = df_pinguinos[‚Äúflipper_length_mm‚Äù].values.reshape(-1,1) 
                  br
                  |Y = df_pinguinos[‚Äúbody_mass_g‚Äù] 
                  br
                  |X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-4.svg" style="max-width: 290px")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso 3")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Posteriormente, se crea una instancia de LinearRegresion y se instruye a la regresi√≥n lineal que aprenda de los datos #[b X_train y Y_train], para lo cual se usa el m√©todo fit para ajustar los par√°metros de la l√≠nea de regresi√≥n a los datos, es decir, se entrena a la regresi√≥n lineal.
            p.fw-bold Para ese fin se utiliza el siguiente c√≥digo:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white regresion = LinearRegression() 
                  br
                  |model = reg.fit(X_train, Y_train)
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-3.svg" style="max-width: 290px")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso 4")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Una vez realizado esto ya se pueden observar los par√°metros que estima la regresi√≥n lineal : 
            p print(‚Äòm = ‚Äò + str(regresion.coef_) + ‚Äò, b = ‚Äò 
              br            
              |+ str(regresion.intercept_)) 
              br              
              |m = [50.41798199], b = -5919.258741821233 , 
            p Los par√°metros obtenidos m y b se reemplazan en la ecuaci√≥n de regresi√≥n y se obtiene:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white ùë¶ = 50.417981ùë• ‚àí5919.25874
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-4.svg" style="max-width: 290px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso 5")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Luego de haber realizado este proceso, ya se puede predecir el resultado de la masa de un ping√ºino con una longitud de una aleta, usando el m√©todo predict de la clase LinearRegression. Si se desea saber cu√°l es la masa aproximada de un ping√ºino que tiene una longitud de la aleta de unos 200 mm, se usa el siguiente c√≥digo:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.text-white longitudAleta =np.array ([200]) 
                  br
                  |prediccion = regresion.predict(longitudAleta.reshape(-1,1)) 
                  br
                  |print (‚ÄòEl valor de la masa de un ping√ºino que tiene longitud de aleta = ‚Äò + str(longitudAleta) + ‚Äò mm es ‚Äò + str(prediccion )) 

                p.text-white.mb-0 El valor de la masa de un ping√ºino que tiene longitud de aleta = [200] mm es [4164.3376571]
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-3.svg" style="max-width: 290px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso 6")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p La ra√≠z cuadrada del coeficiente de determinaci√≥n es R y puede variar entre -1 y 1, conocido como coeficiente de correlaci√≥n de Pearson. Este coeficiente mide el grado de asociaci√≥n lineal entre dos variables X y Y, el signo indica la direcci√≥n de la correlaci√≥n y el valor num√©rico, el grado de correlaci√≥n.
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-4.svg" style="max-width: 290px")
    
    Separador
    #t_3_2.titulo-segundo.color-acento-contenido
      h2 3.2  Algoritmo de clasificaci√≥n con Python

    p La construcci√≥n de los modelos de clasificaci√≥n es una de las tareas m√°s usadas en el aprendizaje autom√°tico, cuando los datos de los cuales se va a aprender cuentan con atributos de entrada y estos se encuentran relacionados con valores discretos, clases o etiquetas.

    .d-flex.flex-wrap.mb-5
      .col-lg-8.order-2.order-lg-1.pe-lg-4.me-xl-auto(data-aos="fade-right")
        .d-flex.flex-wrap.mb-4
          img.mx-auto.d-none.d-md-flex.mb-md-auto(src="@/assets/curso/temas/tema3/img-5.svg" style="max-width: 190px")
          p.ps-md-4.col-md Las tareas para resolver un problema de clasificaci√≥n involucra un conjunto de datos de entrenamiento, en los cuales se tienen puntos de datos etiquetados con sus categor√≠as o clases correctas. Los modelos de clasificaci√≥n m√°s usados son la regresi√≥n log√≠stica, Naive Bayes, los soportes de m√°quinas vectoriales, los modelos no param√©tricos como k vecinos m√°s cercanos, los m√©todos de clasificaci√≥n por medio de √°rboles de decisi√≥n y las redes neuronales.
        p.mb-0.p-3(style="background-color: #FFFAE3") Las aplicaciones de los modelos de clasificaci√≥n son infinitas. Algunos ejemplos son el reconocimiento de im√°genes, el reconocimiento de voz, los juegos de computador, los carros aut√≥nomos, la predicci√≥n de enfermedades, las predicciones financieras como la bolsa de valores, la identificaci√≥n de defectos de fabricaci√≥n, la identificaci√≥n de posibles fraudes bancarios, etc.
      img.mx-auto.mb-4.mb-lg-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-6.png" style="max-width: 400px" data-aos="fade-left")

    Separador
    #t_3_3.titulo-segundo.color-acento-contenido
      h2 3.3  √Årboles de clasificaci√≥n con Python
    
    .d-flex.flex-wrap.mb-5
      img.mx-auto.mb-4.mb-lg-auto.col-lg-4(src="@/assets/curso/temas/tema3/img-7.svg" style="max-width: 400px" data-aos="fade-left")
      .col-lg-8.ps-lg-4.me-xl-auto(data-aos="fade-right")
        p Son muy usados en la planeaci√≥n, la estad√≠stica y el aprendizaje autom√°tico, usa una estructura de √°rbol de condiciones y las consecuencias para evaluar posibles eventos de un problema en particular.

        p Cada cuadrado es un nodo, los nodos de m√°s abajo se denominan las hojas del √°rbol, imaginando un √°rbol al rev√©s. Para iniciar las predicciones se comienza desde la ra√≠z del √°rbol, es decir, desde el nodo superior; cada nodo es evaluado y saltando al siguiente nodo, seg√∫n la decisi√≥n correcta.

        p Un √°rbol de decisiones se usa, entonces, para predecir la clase o el valor de la variable dependiente, aprendiendo de las reglas del √°rbol de decisiones encontradas con los datos de entrenamiento.

        p A continuaci√≥n se explica c√≥mo aplicar el √°rbol de decisiones al ejercicio planteado.

    .tarjeta.p-5(style="background-color: #EBECFF")
      LineaTiempoC.color-acento-contenido(text-small)
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Para aplicar el √°rbol de decisi√≥n al ejercicio que se ha venido trabajando, se observa que se podr√≠a tomar decisiones de clasificaci√≥n usando las variables bill_length_mm y bill_depth_mm para clasificar una especie, entonces, se remueve del dataset las dem√°s caracter√≠sticas. 

            p.fw-bold El c√≥digo que se debe utilizar en este caso es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white datosPicos = df_pinguinos.drop ([‚Äòisland‚Äô, ‚Äòflipper_length_mm‚Äô, ‚Äòbody_mass_g‚Äô, ‚Äòsex‚Äô], axis = 1) pairPlotPicos = sns.pairplot ( datosPicos, hue=‚Äòspecies‚Äô) pairPlotPicos.fig.set_size_inches(9,6.5)
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px" data-aos="fade-left")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-7.pe-lg-4.order-2.order-lg-1
            p El gr√°fico muestra que la especie Adelie puede ser identificada con la longitud del pico (bill_length_mm) y para distinguir entre chinstrap y gentoo se puede realizar con la caracter√≠stica de profundidad del pico (bill_depth_mm).
          img.mx-auto.col-lg-5.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-1.png" style="max-width: 400px" data-aos="fade-left")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Una vez identificadas las caracter√≠sticas que m√°s contribuyen a una clasificaci√≥n de una especie, entonces, se definen las variables predictoras en una variable X y los datos con los resultados o etiquetas en la variable Y.
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white Donde: 
                  br
                  |X = df_pinguinos[[‚Äòbill_length_mm‚Äô, ‚Äòbill_depth_mm‚Äô]]
                  br
                  |Y = df_pinguinos[‚Äòspecies‚Äô]
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-2.svg" style="max-width: 315px" data-aos="fade-left")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Una vez se tienen separadas las variables predictoras y las variables etiquetadas se procede a separar los datos de entrenamiento y prueba con la instrucci√≥n train_test_split, con par√°metro X, Y y test_size=0.2, que significa que se tomar√° el 20 % de los datos para el set de pruebas, por tanto el 80 % se tomar√°n para el set de entrenamiento.
            p.fw-bold Esto se hace a partir del siguiente c√≥digo:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white X_entrenamiento, X_prueba, Y_entrenamiento, Y_prueba = train_test_split(X, Y, test_size = 0.2) print(‚ÄòLos datos de entrenamiento son {} y los datos de prueba son {} ‚Äò.format(X_entrenamiento.shape[0], X_prueba.shape[0])) Los datos de entrenamiento son 266 y los datos de prueba son 6
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px" data-aos="fade-left")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Posteriormente, se define el algoritmo de √°rboles de decisi√≥n con la funci√≥n #[b DecisionTreeClassifier], luego se entrena con los datos de entrenamiento X y Y. Con la funci√≥n fit se realiza una predicci√≥n y se calcula una predicci√≥n con los datos de prueba fijados.

            p El c√≥digo a utilizar es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white from sklearn.tree import DecisionTreeClassifier
                  br
                  |from sklearn import tree algoritmoTree = DecisionTreeClassifier() algoritmoTree.fit (X_entrenamiento, Y_entrenamiento) Y_predTree = algoritmoTree.predict (X_prueba) print(‚ÄòLa Precisi√≥n del algoritmo de √°rboles de decisi√≥n es: {}‚Äô.format(algoritmoTree.score(X_entrenamiento, Y_entrenamiento))) 
                  br
                  br
                  |La precisi√≥n del algoritmo de √°rboles de decisi√≥n es 1.0.
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px" data-aos="fade-left")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Se observa que el algoritmo de clasificaci√≥n con √°rboles de decisi√≥n tiene una precisi√≥n del 100 %.
              br
              |Para realizar una predicci√≥n con √°rboles de clasificaci√≥n con Python, se hace la suposici√≥n que se encuentra un ping√ºino con los siguientes datos:
            .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
              p.mb-0.text-white bill_length_mm = 50 mm
                br
                |'bill_depth_mm' = 21 mm
                br
                |El c√≥digo a utilizar es:
                br
                |algoritmoTree.predict([[50,21]])
                br
                |resultado:
                br
                |array(['Chinstrap'], dtype=object)
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px" data-aos="fade-left")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Si se desea observar el √°rbol de decisi√≥n en pleno se puede hacer de varias formas, una de las cuales es importando la librer√≠a #[b export_graphviz], se definen las variables caracter√≠sticas y las variables label, de esta manera:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white from sklearn.tree import DecisionTreeClassifier, export_graphviz import graphviz
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-4.svg" style="max-width: 315px" data-aos="fade-left")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p El c√≥digo fuente a continuaci√≥n dibuja el √°rbol de decisi√≥n para mejor entendimiento del investigador y se basa en Scikit learn usando la libreria #[b tree.export.graphviz.]
            p El c√≥digo es el siguiente:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white feature_names = [‚Äòbill_length_mm‚Äô,‚Äôbill_depth_mm‚Äô] class_names = [‚ÄòAdelie‚Äô, ‚ÄòChinstrap‚Äô,‚ÄôGentoo‚Äô] datos = tree.export_graphviz(algoritmoTree,out_file=None, feature_names=feature_names, class_names=class_names,filled=True, rounded=True, special_characters=True) graph = graphviz.Source(datos) graph
          img.mx-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-5.svg" style="max-width: 315px" data-aos="fade-left")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Paso")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Se puede observar en el √°rbol generado una primera comparaci√≥n inicial de bill_length_mm <= 42.55 o bill_length_mm > 42.55 y una primera rama con bill_depth_mm <= 15.1 si la primera condici√≥n es verdadera. Luego, se observa en la rama siguiente un primer resultado. Si cumple las dos condiciones anteriores, la especie se clasific√≥ como gentoo y as√≠ sucesivamente. 
            p El algoritmo clasific√≥ en forma autom√°tica estas condiciones de la forma m√°s eficiente posible. Se puede observar un √°rbol resultante bastante complejo pero con #[b scikit-learn] la generaci√≥n es bastante sencilla.
          .col-lg-4.order-1.order-lg-2.text-center
            img.mx-auto.mb-2(src="@/assets/curso/temas/tema3/lt-6.svg" style="max-width: 315px" data-aos="fade-left")
            a(@click="modal1 = true") Ampliar imagen
    ModalA(:abrir-modal.sync="modal1")
      img.mx-auto(src="@/assets/curso/temas/tema3/img-8.svg" data-aos="fade-left")
</template>

<script>
export default {
  name: 'Tema3',
  data: () => ({
    modal1: false,
  }),
  mounted() {
    this.$nextTick(() => {
      this.$aosRefresh()
    })
  },
  updated() {
    this.$aosRefresh()
  },
}
</script>

<style lang="sass">
.bloque-texto-g-edit
  .bloque-texto-g__img
    width: 404px
  .bloque-texto-g__texto
    width: 75%
  @media (max-width: 991px)
    .bloque-texto-g__img
      width: 100%
    .bloque-texto-g__texto
      width: 100%
</style>
