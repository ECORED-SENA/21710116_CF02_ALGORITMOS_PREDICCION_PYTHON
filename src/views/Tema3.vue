<template lang="pug">
.curso-main-container.pb-3
  BannerInterno
  .container.tarjeta.tarjeta--blanca.p-4.p-md-5.mb-5
    .titulo-principal.color-acento-contenido
      .titulo-principal__numero
        span 3
      h1 Algoritmos de aprendizaje supervisado en acci√≥n con Python
    
    p(data-aos="fade-right") Incluyen algoritmos que toman una muestra de datos y sus respectivas salidas, el objetivo principal es que el algoritmo aprenda c√≥mo se relacionan los datos de entrada X y sus correspondientes salidas Y, a partir de un conjunto de entrenamiento escogido para tal fin.

    p.mb-5.fw-bold(data-aos="fade-right") Con el conocimiento adquirido se puede predecir nuevas salidas a trav√©s de nuevos datos X

    .bloque-texto-g.bloque-texto-g-edit.color-primario.p-3.p-sm-4.p-md-5.col-xl-10.mx-auto(data-aos="fade-right")
      .bloque-texto-g__img(
        :style="{'background-image': `url(${require('@/assets/curso/temas/tema3/img-1.png')})`}"
      )
      .bloque-texto-g__texto.p-4
        p.mb-0 Estos algoritmos se llaman supervisados porque el modelo aprendi√≥ de respuestas y etiquetas conocidas de antemano en la fase de entrenamiento. Los m√©todos de aprendizaje supervisado son de dos tipos principales, esto depende del problema que se desea resolver y pueden ser: algoritmos de regresi√≥n y algoritmos de clasificaci√≥n.
    Separador
    #t_3_1.titulo-segundo.color-acento-contenido
      h2 3.1  Algoritmo de regresi√≥n con Python
    
    p(data-aos="fade-right") La regresi√≥n lineal se utiliza para estimar valores reales como ventas, costos, cantidad de llamadas en una central, gastos, etc., en funci√≥n de unas variables predictoras de tipo continuo. <b>La mejor ecuaci√≥n que se ajusta se llama l√≠nea de regresi√≥n y la ecuaci√≥n utilizada es:</b>

    .d-flex.flex-wrap.mb-5
      .col-md-6.d-flex.flex-wrap.order-2.order-md-1
        .d-flex.pe-md-3.mb-3
          .tarjeta.p-3.p-md-4.mb-auto(style="background-color: #24135A;" data-aos="fade-left")
            p.mb-0(style="color: #FFD945") ùëå = ùëöùëã+ùëè
        .d-flex.pe-md-4.mb-4.col-12.col-lg
          .tarjeta.p-3.p-md-4.w-100(style="background-color: #E2F8F0;" data-aos="fade-left")
            p.fw-bold Donde:
            p.mb-0 ùëå: es la variable dependiente.
              br            
              |ùëö: es la pendiente de la l√≠nea de regresi√≥n.
              br              
              |ùëè: es la intersecci√≥n con el eje Y.
        p.pe-md-4(data-aos="fade-right") La regresi√≥n lineal puede ser simple o m√∫ltiple, la primera se caracteriza por tener una variable independiente, contrario a la regresi√≥n m√∫ltiple que se caracteriza por tener m√°s de una variable independiente.
        p.mb-0.pe-lg-4(data-aos="fade-right") Volviendo al ejemplo propuesto se utilizar√° la librer√≠a <em><b style="background-color: #E1E2FC">scikit-learn,</b></em> que es una librer√≠a para el aprendizaje autom√°tico. En el siguiente recurso se pueden identificar los m√≥dulos a implementar y los pasos a seguir:
      img.mx-auto.mx-md-0.col-md-6.col-xl-5.mb-4.mb-md-auto.order-1.order-md-2(src="@/assets/curso/temas/tema3/img-2.png" style="max-width: 492px" data-aos="fade-left")
    
    .tarjeta.p-3.p-md-5(style="background-color: #EBECFF")
      LineaTiempoC.color-acento-contenido(text-small)
        .col-lg-11.mx-auto.d-flex.flex-wrap.align-items-start(titulo="Paso 1")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p(data-aos="fade-right") Lo primero que se debe tener en cuenta es que: 
            p(data-aos="fade-right") linear_model: sirve para entrenar un modelo de Machine Learning de regresi√≥n lineal. 
              br            
              |#[b train_test_split:] sirve para dividir los datos en datos de entrenamiento y datos de prueba. 
              br              
              |#[b metrics:] sirve para medir el desempe√±o del modelo.
            p.fw-bold(data-aos="fade-right") En ese orden de ideas el c√≥digo a utilizar es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-left")
                p.mb-0.text-white import seaborn as sns 
                  br                
                  |import matplotlib.pyplot as plt 
                  br                  
                  |from sklearn.linear_model import LinearRegression 
                  br                  
                  |from sklearn.model_selection import train_test_split 
                  br                  
                  |from sklearn.metrics import mean_squared_error, r2_score
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-3.svg" style="max-width: 290px" data-aos="fade-left")

        .col-lg-11.mx-auto.d-flex.flex-wrap.align-items-start(titulo="Paso 2")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Para entrenar el modelo con esta librer√≠a inicialmente se carga el valor de X con los datos de la longitud de la aleta #[b (flipper_length_mm)], y Y con los datos de masa del ping√ºino #[b (body_mass_g)], posteriormente se obtiene un subconjunto de datos que ser√°n el dataset de entrenamiento y el set de pruebas en las variables #[b X_train, Y_train, X_test, Y_test] en una proporci√≥n de 80 % para los datos de entrenamiento y 20 % para los datos de prueba.
            p.fw-bold El c√≥digo a utilizar es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white X = df_pinguinos[‚Äú flipper_length_mm ‚Äù].values.reshape(-1,1) 
                  br
                  |Y = df_pinguinos[‚Äúbody_mass_g‚Äù] 
                  br
                  |X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42)
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-4.svg" style="max-width: 290px")

        .col-lg-11.mx-auto.d-flex.flex-wrap.align-items-start(titulo="Paso 3")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Posteriormente, se crea una instancia de LinearRegresion y se instruye a la regresi√≥n lineal que aprenda de los datos #[b X_train y Y_train], para lo cual se usa el m√©todo fit para ajustar los par√°metros de la l√≠nea de regresi√≥n a los datos, es decir, se entrena a la regresi√≥n lineal.
            p.fw-bold Para ese fin se utiliza el siguiente c√≥digo:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white regresion = LinearRegression() 
                  br
                  |model = reg.fit(X_train, Y_train)
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-3.svg" style="max-width: 290px")

        .col-lg-11.mx-auto.d-flex.flex-wrap.align-items-start(titulo="Paso 4")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Una vez realizado esto ya se pueden observar los par√°metros que estima la regresi√≥n lineal : 
            p print(‚Äòm = ‚Äò + str(regresion.coef_) + ‚Äò, b = ‚Äò 
              br            
              |+ str(regresion.intercept_)) 
              br              
              |m = [50.41798199], b = -5919.258741821233 , 
            p Los par√°metros obtenidos m y b se reemplazan en la ecuaci√≥n de regresi√≥n y se obtiene:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white ùë¶ = 50.417981ùë• ‚àí5919.25874
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-4.svg" style="max-width: 290px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap.align-items-start(titulo="Paso 5")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Luego de haber realizado este proceso, ya se puede predecir el resultado de la masa de un ping√ºino con una longitud de una aleta, usando el m√©todo predict de la clase LinearRegression. Si se desea saber cu√°l es la masa aproximada de un ping√ºino que tiene una longitud de la aleta de unos 200 mm, se usa el siguiente c√≥digo:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.text-white longitudAleta =np.array ([200]) 
                  br
                  |prediccion = regresion.predict( longitudAleta.reshape(-1,1) ) 
                  br
                  |print (‚ÄòEl valor de la masa de un ping√ºino que tiene longitud de aleta = ‚Äò + str(longitudAleta) + ‚Äò mm es ‚Äò + str(prediccion )) 

                p.text-white.mb-0 El valor de la masa de un ping√ºino que tiene longitud de aleta = [200] mm es [4164.3376571]
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-3.svg" style="max-width: 290px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap.align-items-start(titulo="Paso 6")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p La ra√≠z cuadrada del coeficiente de determinaci√≥n es R y puede variar entre -1 y 1, conocido como coeficiente de correlaci√≥n de Pearson. Este coeficiente mide el grado de asociaci√≥n lineal entre dos variables X y Y, el signo indica la direcci√≥n de la correlaci√≥n y el valor num√©rico, el grado de correlaci√≥n.
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-4.svg" style="max-width: 290px")
    
    Separador
    #t_3_2.titulo-segundo.color-acento-contenido
      h2 3.2  Algoritmo de clasificaci√≥n con Python

    p(data-aos="fade-right") La construcci√≥n de los modelos de clasificaci√≥n es una de las tareas m√°s usadas en el aprendizaje autom√°tico, cuando los datos de los cuales se va a aprender cuentan con atributos de entrada y estos se encuentran relacionados con valores discretos, clases o etiquetas.

    .d-flex.flex-wrap.mb-5
      .col-lg-8.order-2.order-lg-1.pe-lg-4.me-xl-auto(data-aos="fade-right")
        .d-flex.flex-wrap.mb-4
          img.mx-auto.d-none.d-md-flex.mb-md-auto(src="@/assets/curso/temas/tema3/img-5.svg" style="max-width: 190px")
          p.ps-md-4.col-md Las tareas para resolver un problema de clasificaci√≥n involucra un conjunto de datos de entrenamiento, en los cuales se tienen puntos de datos etiquetados con sus categor√≠as o clases correctas. Los modelos de clasificaci√≥n m√°s usados son la regresi√≥n log√≠stica, Naive Bayes, los soportes de m√°quinas vectoriales, los modelos no param√©tricos como k vecinos m√°s cercanos, los m√©todos de clasificaci√≥n por medio de √°rboles de decisi√≥n y las redes neuronales.
        p.mb-0.p-3(style="background-color: #FFFAE3") Las aplicaciones de los modelos de clasificaci√≥n son infinitas. Algunos ejemplos son el reconocimiento de im√°genes, el reconocimiento de voz, los juegos de computador, los carros aut√≥nomos, la predicci√≥n de enfermedades, las predicciones financieras como la bolsa de valores, la identificaci√≥n de defectos de fabricaci√≥n, la identificaci√≥n de posibles fraudes bancarios, etc.
      img.mx-auto.mb-4.mb-lg-auto.col-lg-4.order-1.order-lg-2(src="@/assets/curso/temas/tema3/img-6.png" style="max-width: 400px" data-aos="fade-left")

    Separador
    #t_3_3.titulo-segundo.color-acento-contenido
      h2 3.3  √Årboles de clasificaci√≥n con Python
    
    .d-flex.flex-wrap.mb-5
      img.mx-auto.mb-4.mb-lg-auto.col-lg-4(src="@/assets/curso/temas/tema3/img-7.svg" style="max-width: 400px" data-aos="fade-left")
      .col-lg-8.ps-lg-4.me-xl-auto(data-aos="fade-right")
        p Son muy usados en la planeaci√≥n, la estad√≠stica y el aprendizaje autom√°tico, usa una estructura de √°rbol de condiciones y las consecuencias para evaluar posibles eventos de un problema en particular.

        p Cada cuadrado es un nodo, los nodos de m√°s abajo se denominan las hojas del √°rbol, imaginando un √°rbol al rev√©s. Para iniciar las predicciones se comienza desde la ra√≠z del √°rbol, es decir, desde el nodo superior; cada nodo es evaluado y saltando al siguiente nodo, seg√∫n la decisi√≥n correcta.

        p Un √°rbol de decisiones se usa, entonces, para predecir la clase o el valor de la variable dependiente, aprendiendo de las reglas del √°rbol de decisiones encontradas con los datos de entrenamiento.

        p A continuaci√≥n se explica c√≥mo aplicar el √°rbol de decisiones al ejercicio planteado.

    .tarjeta.p-3.p-md-5(style="background-color: #EBECFF")
      LineaTiempoC.color-acento-contenido(text-small)
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Decisiones de clasificaci√≥n")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p(data-aos="fade-right") Para aplicar el √°rbol de decisi√≥n al ejercicio que se ha venido trabajando, se observa que se podr√≠a tomar decisiones de clasificaci√≥n usando las variables bill_length_mm y bill_depth_mm para clasificar una especie, entonces, se remueve del dataset las dem√°s caracter√≠sticas. 

            p.fw-bold(data-aos="fade-right") El c√≥digo que se debe utilizar en este caso es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;" data-aos="fade-right")
                p.mb-0.text-white datosPicos = df_pinguinos.drop ([‚Äòisland‚Äô, ‚Äòflipper_length_mm‚Äô, ‚Äòbody_mass_g‚Äô, ‚Äòsex‚Äô], axis = 1) pairPlotPicos = sns.pairplot ( datosPicos, hue=‚Äòspecies‚Äô) pairPlotPicos.fig.set_size_inches(9, 6.5)
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px" data-aos="fade-left")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Gr√°fico de pares")
          .col-lg-7.pe-lg-4.order-2.order-lg-1
            p El gr√°fico muestra que la especie Adelie puede ser identificada con la longitud del pico (bill_length_mm) y para distinguir entre chinstrap y gentoo se puede realizar con la caracter√≠stica de profundidad del pico (bill_depth_mm).
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-1.png" style="max-width: 400px")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Variables predictoras")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Una vez identificadas las caracter√≠sticas que m√°s contribuyen a una clasificaci√≥n de una especie, entonces, se definen las variables predictoras en una variable X y los datos con los resultados o etiquetas en la variable Y.
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white Donde: 
                  br
                  |X = df_pinguinos[[‚Äòbill_length_mm‚Äô, ‚Äòbill_depth_mm‚Äô]]
                  br
                  |Y = df_pinguinos[‚Äòspecies‚Äô]
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-2.svg" style="max-width: 315px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Variables predictoras")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Una vez se tienen separadas las variables predictoras y las variables etiquetadas se procede a separar los datos de entrenamiento y prueba con la instrucci√≥n train_test_split, con par√°metro X, Y y test_size=0.2, que significa que se tomar√° el 20 % de los datos para el set de pruebas, por tanto el 80 % se tomar√°n para el set de entrenamiento.
            p.fw-bold Esto se hace a partir del siguiente c√≥digo:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white X_entrenamiento, X_prueba, Y_entrenamiento, Y_prueba = train_test_split(X, Y, test_size = 0.2) print(‚ÄòLos datos de entrenamiento son {} y los datos de prueba son {} ‚Äò.format(X_entrenamiento.shape[0], X_prueba.shape[0])) Los datos de entrenamiento son 266 y los datos de prueba son 6
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Algoritmo")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Posteriormente, se define el algoritmo de √°rboles de decisi√≥n con la funci√≥n #[b DecisionTreeClassifier], luego se entrena con los datos de entrenamiento X y Y. Con la funci√≥n fit se realiza una predicci√≥n y se calcula una predicci√≥n con los datos de prueba fijados.
            p El c√≥digo a utilizar es:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.text-white from sklearn.tree import DecisionTreeClassifier
                  br
                  |from sklearn import tree algoritmoTree = DecisionTreeClassifier() algoritmoTree.fit (X_entrenamiento, Y_entrenamiento) Y_predTree = algoritmoTree.predict (X_prueba) print(‚ÄòLa Precisi√≥n del algoritmo de √°rboles de decisi√≥n es: {}‚Äô.format(algoritmoTree.score( X_entrenamiento, Y_entrenamiento ))) 
                p.text-white La precisi√≥n del algoritmo de √°rboles de decisi√≥n es 1.0.
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Realizar la predicci√≥n")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Se observa que el algoritmo de clasificaci√≥n con √°rboles de decisi√≥n tiene una precisi√≥n del 100 %.
              br
              |Para realizar una predicci√≥n con √°rboles de clasificaci√≥n con Python, se hace la suposici√≥n que se encuentra un ping√ºino con los siguientes datos:
            .tarjeta.px-4.py-2(style="background-color: #24135A;")
              p.mb-0.text-white bill_length_mm = 50 mm
                br
                |'bill_depth_mm' = 21 mm
                br
                |El c√≥digo a utilizar es:
                br
                |algoritmoTree.predict([[50,21]])
                br
                |resultado:
                br
                |array(['Chinstrap'], dtype=object)
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-3.svg" style="max-width: 315px")

        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Realizar la predicci√≥n")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Si se desea observar el √°rbol de decisi√≥n en pleno se puede hacer de varias formas, una de las cuales es importando la librer√≠a #[b export_graphviz], se definen las variables caracter√≠sticas y las variables label, de esta manera:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white from sklearn.tree import DecisionTreeClassifier, export_graphviz import graphviz
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-4.svg" style="max-width: 315px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="Dibujo del √°rbol")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p El c√≥digo fuente a continuaci√≥n dibuja el √°rbol de decisi√≥n para mejor entendimiento del investigador y se basa en Scikit learn usando la libreria #[b tree.export.graphviz.]
            p El c√≥digo es el siguiente:
            .d-flex.pe-md-3.mb-3
              .tarjeta.px-4.py-2(style="background-color: #24135A;")
                p.mb-0.text-white feature_names = [‚Äòbill_length_mm‚Äô, ‚Äôbill_depth_mm‚Äô] class_names = [‚ÄòAdelie‚Äô, ‚ÄòChinstrap‚Äô,‚ÄôGentoo‚Äô] datos = tree.export_graphviz(algoritmoTree, out_file=None, feature_names=feature_names, class_names = class_names,filled=True, rounded=True, special_characters=True) graph = graphviz.Source(datos) graph
          img.mx-auto.col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2(src="@/assets/curso/temas/tema3/lt-5.svg" style="max-width: 315px")
        
        .col-lg-11.mx-auto.d-flex.flex-wrap(titulo="√Årbol generado")
          .col-lg-8.pe-lg-4.order-2.order-lg-1
            p Se puede observar en el √°rbol generado una primera comparaci√≥n inicial de bill_length_mm <= 42.55 o bill_length_mm > 42.55 y una primera rama con bill_depth_mm <= 15.1 si la primera condici√≥n es verdadera. Luego, se observa en la rama siguiente un primer resultado. Si cumple las dos condiciones anteriores, la especie se clasific√≥ como gentoo y as√≠ sucesivamente. 
            p El algoritmo clasific√≥ en forma autom√°tica estas condiciones de la forma m√°s eficiente posible. Se puede observar un √°rbol resultante bastante complejo pero con #[b scikit-learn] la generaci√≥n es bastante sencilla.
          .col-lg-4.mb-4.mb-lg-auto.order-1.order-lg-2.text-center
            img.mx-auto.mb-2(src="@/assets/curso/temas/tema3/lt-6.svg" style="max-width: 315px")
            a(@click="modal1 = true") Ampliar imagen
    
    ModalA(:abrir-modal.sync="modal1")
      img.mx-auto(src="@/assets/curso/temas/tema3/img-8.svg" data-aos="fade-left")
    
    Separador
    #t_3_4.titulo-segundo.color-acento-contenido
      h2 3.4 K vecinos m√°s cercanos con Python
    
    p Trabaja comparando la distancia de una observaci√≥n a consultar con otras muestras del conjunto de entrenamiento y seleccionando los k vecinos m√°s cercanos. La mayor√≠a de las clases a las que pertenecen esos vecinos m√°s cercanos ser√° la clase a la que pertenezca la observaci√≥n a consultar.

    p.fw-bold.mb-5 A continuaci√≥n  se puede observar c√≥mo hacer uso de dicho algoritmo.

    .container-100.py-5(style="background: linear-gradient(180deg, rgba(168,221,255,1) 0%, rgba(213,213,255,1) 100%);")
      .d-flex.align-items-start.mb-4
        .id-circular.mb-2.mx-auto(style="background: linear-gradient(180deg, rgba(179,26,143,1) 0%, rgba(254,17,126,1) 100%);" data-aos="fade-right")
          span 1
        .col.ps-3
          p Lo primero que se debe hacer es importar las librer√≠as necesarias para trabajar con el algoritmo k-vecinos m√°s cercanos, para ese fin debe usarse el siguiente comando:
          .d-flex.pe-md-3.mb-3
            .tarjeta.px-4.py-4(style="background-color: #24135A;" data-aos="fade-right")
              p.mb-0.text-white from sklearn.neighbors import KNeighborsClassifier
      
      .d-flex.align-items-start.mb-4
        .id-circular.mb-2.mx-auto(style="background: linear-gradient(180deg, rgba(179,26,143,1) 0%, rgba(254,17,126,1) 100%);" data-aos="fade-right")
          span 2
        .col.ps-3(style="max-width: calc(100% - 42px);")
          p Una vez importada la librer√≠a se define el algoritmo #[b KNeighborsClassifier(n_neighbors=5)], con un k escogido en este caso inicie con k=5 vecinos, luego se entrena usando la funci√≥n fit y se realiza una predicci√≥n usando los datos de #[b X_prueba]. Una forma de medir la precisi√≥n del algoritmo es usar la funci√≥n score. 
          p El c√≥digo fuente muestra la predicci√≥n con k-vecinos m√°s cercanos.
          .d-flex.pe-md-3.mb-3
            .tarjeta.px-4.py-4.w-100(style="background-color: #24135A; overflow: auto" data-aos="fade-right")
              p.mb-0.text-white algoritmoKnn = KNeighborsClassifier(n_neighbors=5)
                br
                |algoritmoKnn.fit(X_entrenamiento, Y_entrenamiento)
                br
                |Y_predKnn = algoritmoKnn.predict(X_prueba)
                br
                |print(‚ÄòPrecisi√≥n Vecinos m√°s Cercanos: {}‚Äô.format(algoritmoKnn.score(X_entrenamiento, Y_entrenamiento)))
                br
                |Resultado: Precisi√≥n vecinos m√°s cercanos: 0.9699248120300752

      .d-flex.align-items-start.mb-4
        .id-circular.mb-2.mx-auto(style="background: linear-gradient(180deg, rgba(179,26,143,1) 0%, rgba(254,17,126,1) 100%);" data-aos="fade-right")
          span 3
        .col.ps-3
          p Para realizar una predicci√≥n k vecinos m√°s cercanos con Python se hace la suposici√≥n que se encuentra un ping√ºino con los siguientes datos: bill_length_mm = 50 mm ‚Äòbill_depth_mm‚Äô = 21 mm
          .d-flex.pe-md-3.mb-3
            .tarjeta.px-4.py-4(style="background-color: #24135A;" data-aos="fade-right")
              p.mb-0.text-white res=algoritmoKnn.predict([[50,21]])
                br
                |print(‚ÄúLa especie puede ser : ‚Äú)
                br
                |if res==‚ÄòAdelie‚Äô: print(‚ÄúAdelie‚Äù)
                br
                |elif res==‚ÄòGentoo‚Äô: print(‚ÄúGentoo‚Äù)
                br
                |elif res==‚ÄòChinstrap‚Äô: print(‚ÄúChinstrap‚Äù)
                br
                |Resultado: La especie puede ser Chinstrap
    
      .d-flex.align-items-start.mb-4
        .id-circular.mb-2.mx-auto(style="background: linear-gradient(180deg, rgba(179,26,143,1) 0%, rgba(254,17,126,1) 100%);" data-aos="fade-right")
          span 4
        .col.ps-3
          p El resultado de una predicci√≥n con estos datos es:
          .d-flex.pe-md-3.mb-3
            .tarjeta.px-4.py-4(style="background-color: #24135A;" data-aos="fade-right")
              p.mb-0.text-white bill_length_mm = 50 y bill_depth_mm = 21, es decir, que el ping√ºino es de tipo Chinstrap


    Separador
    #t_3_5.titulo-segundo.color-acento-contenido
      h2 3.5 Redes neuronales con Python
    
    p.mb-5(data-aos="fade-right") Son una t√©cnica de inteligencia artificial basada en la forma como funcionan las neuronas en el cerebro. Consiste en unidades llamadas neuronas, las cuales tienen algunas caracter√≠sticas particulares, las cuales se muestran a continuaci√≥n.

    ImagenInfografica.color-acento-botones.mb-5.col-xl-8.col-lg-10.mx-auto
      template(v-slot:imagen)
        figure
          img(src='@/assets/curso/temas/tema3/img-9.svg' alt='')

      .tarjeta.color-acento-botones.p-4(x="9%" y="6.5%" numero="" style='background-color: #EFF0FE; border: 1px solid #9697F8')
        p Cada neurona puede realizar tres operaciones principales:
        ul.mb-0.lista-ul
          li.mb-1
            i.lista-ul__vineta(style="color: #3ECE9B")
            | Tomar la suma ponderada de las entradas.
          li.mb-1
            i.lista-ul__vineta(style="color: #3ECE9B")
            | Agregar un peso constante adicional a esta suma ponderada.
          li.mb-1
            i.lista-ul__vineta(style="color: #3ECE9B")
            | Aplicar una funci√≥n no lineal a la salida, usando una funci√≥n de activaci√≥n predefinida.
      .tarjeta.color-acento-botones.p-4(x="63%" y="4.5%" numero="" style='background-color: #EFF0FE; border: 1px solid #9697F8')
        p.mb-0 Tiene una o m√°s entradas, los datos de entrada son expresados como n√∫meros de punto flotante.
      .tarjeta.color-acento-botones.p-4(x="4.5%" y="44.5%" numero="" style='background-color: #EFF0FE; border: 1px solid #9697F8')
        p.mb-0 Se separan en capas. Cada capa puede tener una o m√°s neuronas. Una red tiene al menos una capa de entrada, que es donde se reciben los datos y una capa de salida que tiene el resultado calculado.
      .tarjeta.color-acento-botones.p-4(x="86%" y="44.5%" numero="" style='background-color: #EFF0FE; border: 1px solid #9697F8')
        p.mb-0 Retornar un valor de salida que es un n√∫mero de punto flotante.
      .tarjeta.color-acento-botones.p-4(x="66%" y="85%" numero="" style='background-color: #EFF0FE; border: 1px solid #9697F8')
        p.mb-0 Retornar un valor de salida que es un n√∫mero de punto flotante.
      .tarjeta.color-acento-botones.p-4(x="41%" y="96%" numero="" style='background-color: #EFF0FE; border: 1px solid #9697F8')
        p.mb-0 Las neuronas se unen a trav√©s de diferentes conexiones.


    .tarjeta.p-3.col-xl-10.mx-auto(style="background: linear-gradient(180deg, #0067D5 0%, #550AC3 100%);")
      .row.justify-content-around.align-items-center
        .col-auto
          img(src="@/assets/curso/temas/tema3/img-10.svg").img65
        .col
          .row.justify-content-between.align-items-center
            .col.mb-3.mb-sm-0.text-white
              h4.mb-1 Ejemplo de redes neuronales
              p.mb-0.text-small Revise el siguiente documento en el que se muestra un ejemplo sencillo con Python, haciendo uso de las redes neuronales.
            .col-sm-auto
              a.boton.color-acento-botones(:href="obtenerLink('/downloads/CF02_3_5_imagen_interactiva_caracteristicas_redes_neuronales.docx')" target="_blank")
                span Descargar
                i.fas.fa-file-download

</template>

<script>
export default {
  name: 'Tema3',
  data: () => ({
    modal1: false,
  }),
  mounted() {
    this.$nextTick(() => {
      this.$aosRefresh()
    })
  },
  updated() {
    this.$aosRefresh()
  },
}
</script>

<style lang="sass">
.bloque-texto-g-edit
  .bloque-texto-g__img
    width: 404px
  .bloque-texto-g__texto
    width: 75%
  @media (max-width: 991px)
    .bloque-texto-g__img
      width: 100%
    .bloque-texto-g__texto
      width: 100%
</style>
